{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03 Keras Tuner.ipynb","provenance":[{"file_id":"1FeBOfPhD5c2bHcMqpitPSAujA_HIm1F-","timestamp":1611801937965},{"file_id":"1GR-ruMum1b26gyxxAr5R01iKvqAzN6yZ","timestamp":1611725422146}],"collapsed_sections":["vCn9n7sKfeZQ","Jc2nMTlrjAUW","WnpYDBdd_vUV","yyPWPJmhtLgj"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fTuOBLppfF9s"},"source":["### * \\[important] This notebook is **only for Colab-execution**, please use colaboratory to test following codes.\n","### * \\[important] Change runtime type to GPU first & execute following cells\n","### * Official Github repository & documents @ https://github.com/keras-team/keras-tuner\n","### * Keras-tuner Basic tutorial (TF official document) @ https://www.tensorflow.org/tutorials/keras/keras_tuner\n","\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"vCn9n7sKfeZQ"},"source":["<br>\n","\n","## 0. Install Keras-Tuner"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"528U3VTVScOH","executionInfo":{"elapsed":6594,"status":"ok","timestamp":1611879085837,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"0032a680-6bda-471e-bab4-6a240029a2cd"},"source":["!pip install -q -U keras-tuner"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 23.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n","\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2EZvxEozygAh"},"source":["* Following codes are tested under **Tensorflow==2.3.0 & KerasTuner==1.0.2**\n","* If some codes are not working, try install tf & kerastuner with above version."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIbveD8FbKLO","executionInfo":{"elapsed":3671,"status":"ok","timestamp":1611879137387,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"9b34a5d3-0e7e-4e04-a6c6-23ac49107152"},"source":["import tensorflow as tf\n","import kerastuner as kt\n","\n","print(tf.__version__)  # 수업시간에는 2.3.0\n","print(kt.__version__)  # 수업시간에는 1.0.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.1\n","1.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jc2nMTlrjAUW"},"source":["<br>\n","\n","## 1-1. Bayesian HPO with Keras-tuner"]},{"cell_type":"code","metadata":{"id":"ATb8bn-ZayvO"},"source":["import tensorflow as tf\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","from tensorflow import keras \n","from tensorflow.keras import layers\n","\n","import kerastuner as kt\n","import numpy as np\n","import IPython"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jmk7xewLT740"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3uicvx7a_oG","executionInfo":{"elapsed":22068,"status":"ok","timestamp":1611886206082,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"73b1e604-23e4-4bf0-8d49-12a76a521045"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3TNYcRyT7ow","executionInfo":{"elapsed":1566,"status":"ok","timestamp":1611794247828,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"},"user_tz":-540},"outputId":"2034f98a-2076-4d36-bd55-364010985d57"},"source":["df1_path=\"/content/drive/MyDrive/genres_v2.csv\"\r\n","df2_path=\"/content/drive/MyDrive/playlists.csv\"\r\n","df = pd.read_csv(df1_path, encoding='utf-8')\r\n","df2 = pd.read_csv(df2_path, encoding='utf-8')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLG6uN8OUe_l","executionInfo":{"elapsed":2292,"status":"ok","timestamp":1611886211149,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"b646eb8e-0f61-4810-dd6a-263f21c47691"},"source":["# 데이터 가져오기\r\n","train_data = np.load('/content/drive/My Drive/semi3/HSK/X_train_pro.npy')\r\n","test_data = np.load('/content/drive/My Drive/semi3/HSK/X_test_pro.npy')\r\n","train_label = np.load('/content/drive/My Drive/semi3/HSK/y_train_pro.npy')\r\n","test_label = np.load('/content/drive/My Drive/semi3/HSK/y_test_pro.npy')\r\n","\r\n","print(train_data.shape)\r\n","print(test_data.shape)\r\n","print(train_label.shape)\r\n","print(test_label.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(29613, 28)\n","(12692, 28)\n","(29613, 15)\n","(12692, 15)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGSeDCk7gGql","executionInfo":{"elapsed":794,"status":"ok","timestamp":1611879463383,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"2c0e0022-e161-4936-9845-f66be540548d"},"source":["train_label[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"b2M1Op-Hb7uI"},"source":["# # 첫번째 모델: Spotify_hyper_1\n","# # 2) Build the hyper-model\n","# # Available HyperParameter search spaces (https://j.mp/2IXPzh7) : Int, Float, Boolean, Choice, Fixed\n","\n","# def build_hyper_model(hp):\n","    \n","#     model = keras.Sequential()\n","#     # model.add(layers.Flatten(input_shape=(28, 28))) # change 2-dims MNIST dataset to 1-dim \n","        \n","#     # Tune the number of hidden layer (Choose an optimal value between 1~3)\n","#     for i in range(hp.Int('num_layers', min_value=3, max_value=7)): \n","#         # Tune the number of perceptrons in a dense layer (Choose an optimal value between 32~512) \n","#         hp_units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32) # 32:512 & step 32, all parameter names should be unique (we name the inner parameters 'units_' + str(i))\n","#         hp_activations = hp.Choice('activation_' + str(i), values=['relu', 'elu'])\n","#         model.add(layers.Dense(units = hp_units, activation = hp_activations))\n","\n","#     model.add(layers.Dense(15, activation='softmax')) # class 10 : 0~9\n","\n","#     # Tune the learning rate for the optimizer (Choose an optimal value from 0.01, 0.001, or 0.0001)\n","#     hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n","    \n","#     model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n","#                 loss = keras.losses.CategoricalCrossentropy(), # use sparse c.c when our labels are looks like \"1\" (single integer), not \"[1,0,0]\" (one-hot vector) (@ http://j.mp/2XS0jmv)\n","#                 metrics = ['accuracy'])\n","    \n","#     return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3FJBXPzzzNq"},"source":["# 두번째 모델: Spotify_hyper_2\r\n","\r\n","def build_hyper_model(hp):\r\n","    \r\n","    model = keras.Sequential()\r\n","    # model.add(layers.Flatten(input_shape=(28, 28))) # change 2-dims MNIST dataset to 1-dim \r\n","        \r\n","    # Tune the number of hidden layer (Choose an optimal value between 1~3)\r\n","    for i in range(hp.Int('num_layers', min_value=1, max_value=10)): \r\n","        # Tune the number of perceptrons in a dense layer (Choose an optimal value between 32~512) \r\n","        hp_units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32) # 32:512 & step 32, all parameter names should be unique (we name the inner parameters 'units_' + str(i))\r\n","        hp_activations = hp.Choice('activation_' + str(i), values=['relu', 'elu'])\r\n","        model.add(layers.Dense(units = hp_units, activation = hp_activations))\r\n","\r\n","    model.add(layers.Dense(15, activation='softmax')) # class 10 : 0~9\r\n","\r\n","    # Tune the learning rate for the optimizer (Choose an optimal value from 0.01, 0.001, or 0.0001)\r\n","    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \r\n","    \r\n","    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\r\n","                loss = keras.losses.CategoricalCrossentropy(), # use sparse c.c when our labels are looks like \"1\" (single integer), not \"[1,0,0]\" (one-hot vector) (@ http://j.mp/2XS0jmv)\r\n","                metrics = ['accuracy'])\r\n","    \r\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sa3OXBWtc3Wf","executionInfo":{"elapsed":6405,"status":"ok","timestamp":1611879598035,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"1c1d8a58-6465-46e1-d78e-963bebb1a899"},"source":["# 3) Select tuner and compile it\n","# Available tuners (https://j.mp/39cWz4n) : kt.BayesianOptimization / kt.Hyperband / kt.RandomSearch / kt.Sklearn (https://j.mp/3nSJn8O)\n","\n","tuner = kt.BayesianOptimization(build_hyper_model,\n","                                objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n","                                max_trials = 10, # 서로 다른 Hyper-params 조합으로 시도할 총 Trial 횟수 설정\n","                                directory = 'test_prac_dir', # Path to the working directory\n","                                project_name = 'Spotify_hyper_2') # Name to use as directory name for files saved by this Tuner\n","\n","# tuner = kt.Hyperband(build_hyper_model,\n","#                      objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n","#                      max_epochs = 5, # 최대 epoch 수 설정, epoch 수 자체도 지정한 최대 횟수 내에서 변화시켜가며 테스트를 진행함 (epochs to train one model) \n","#                      directory = 'test_prac_dir', # Path to the working directory\n","#                      project_name = 'MNIST_hyper_1') # Name to use as directory name for files saved by this Tuner\n","\n","tuner.search_space_summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Search space summary\n","Default search space size: 4\n","num_layers (Int)\n","{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': None}\n","units_0 (Int)\n","{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n","activation_0 (Choice)\n","{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n","learning_rate (Choice)\n","{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woRJd7mIdSSV","executionInfo":{"elapsed":772962,"status":"ok","timestamp":1611880391404,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"c314170f-fb2e-40ef-c4d8-0256c996cae1"},"source":["# 4) Train the model\n","\n","tuner.search(train_data, train_label, epochs=20, validation_data = (test_data, test_label)) # epochs == learning epoch for training a single model(epoch for each trial) \n","\n","\n","# # 아래와 같이 별도의 클래스로 콜백을 정의하여 search 함수에서 활용하면 모든 학습 단계 종료 후 학습 중 발생한 출력 결과를 자동으로 지워낼 수 있습니다.\n","# class ClearTrainingOutput(tf.keras.callbacks.Callback):\n","#   def on_train_end(*args, **kwargs):\n","#     IPython.display.clear_output(wait = True)\n","\n","# tuner.search(x_train, y_train, epochs = 7, validation_data = (x_test, y_test), callbacks = [ClearTrainingOutput()]) # epochs == learning epoch for training a single model "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trial 10 Complete [00h 01m 16s]\n","val_accuracy: 0.6514339447021484\n","\n","Best val_accuracy So Far: 0.6705011129379272\n","Total elapsed time: 00h 12m 52s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDlJzL14GVXR","executionInfo":{"elapsed":783,"status":"ok","timestamp":1611880415172,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"e9d04dd8-c040-424c-c493-c1b101eda8fb"},"source":["# 5) Check the result \n","\n","tuner.results_summary(num_trials=3) # Show \"n\" best trial results"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Results summary\n","Results in test_prac_dir/Spotify_hyper_2\n","Showing 3 best trials\n","Objective(name='val_accuracy', direction='max')\n","Trial summary\n","Hyperparameters:\n","num_layers: 10\n","units_0: 512\n","activation_0: relu\n","learning_rate: 0.0001\n","units_1: 512\n","activation_1: relu\n","units_2: 32\n","activation_2: relu\n","units_3: 32\n","activation_3: relu\n","units_4: 32\n","activation_4: relu\n","units_5: 32\n","activation_5: relu\n","units_6: 32\n","activation_6: elu\n","units_7: 32\n","activation_7: elu\n","units_8: 512\n","activation_8: relu\n","units_9: 512\n","activation_9: elu\n","Score: 0.6705011129379272\n","Trial summary\n","Hyperparameters:\n","num_layers: 10\n","units_0: 512\n","activation_0: elu\n","learning_rate: 0.0001\n","units_1: 512\n","activation_1: elu\n","units_2: 32\n","activation_2: relu\n","units_3: 32\n","activation_3: relu\n","units_4: 512\n","activation_4: relu\n","units_5: 32\n","activation_5: elu\n","units_6: 32\n","activation_6: relu\n","units_7: 32\n","activation_7: relu\n","units_8: 32\n","activation_8: elu\n","units_9: 512\n","activation_9: elu\n","Score: 0.6691616773605347\n","Trial summary\n","Hyperparameters:\n","num_layers: 9\n","units_0: 256\n","activation_0: relu\n","learning_rate: 0.001\n","units_1: 32\n","activation_1: relu\n","units_2: 32\n","activation_2: relu\n","units_3: 32\n","activation_3: relu\n","units_4: 32\n","activation_4: relu\n","units_5: 32\n","activation_5: relu\n","units_6: 32\n","activation_6: relu\n","units_7: 32\n","activation_7: relu\n","units_8: 32\n","activation_8: relu\n","Score: 0.6667191982269287\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFbk0Bvo36HR","executionInfo":{"elapsed":817,"status":"ok","timestamp":1611880458432,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"a33ab93b-fc9e-4e6a-dbfa-05f1d0107cbb"},"source":["# Check top-3 trials' hyper-params\n","\n","top3_models = tuner.get_best_hyperparameters(num_trials=3)\n","# print(tuner.get_best_hyperparameters(num_trials=3)[0].space) # 특정 Trial의 Search-space 를 확인할 수 있음\n","# print(tuner.get_best_hyperparameters(num_trials=3)[0].values) # 특정 Trial에 적용된 Hyper-params를 확인할 수 있음\n","\n","for idx, model in enumerate(top3_models):\n","    print('Model performance rank :', idx)\n","    print(model.values)\n","    print()\n","\n","\n","# Check the best trial's hyper-params\n","\n","best_hps = top3_models[0]\n","\n","print(\"\"\"\n","The hyperparameter search is complete. \n","* Optimal # of layers : {}\n","* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n","\n","for layer_num in range(best_hps.get('num_layers')):\n","    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n","    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model performance rank : 0\n","{'num_layers': 10, 'units_0': 512, 'activation_0': 'relu', 'learning_rate': 0.0001, 'units_1': 512, 'activation_1': 'relu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 32, 'activation_3': 'relu', 'units_4': 32, 'activation_4': 'relu', 'units_5': 32, 'activation_5': 'relu', 'units_6': 32, 'activation_6': 'elu', 'units_7': 32, 'activation_7': 'elu', 'units_8': 512, 'activation_8': 'relu', 'units_9': 512, 'activation_9': 'elu'}\n","\n","Model performance rank : 1\n","{'num_layers': 10, 'units_0': 512, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 512, 'activation_1': 'elu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 32, 'activation_3': 'relu', 'units_4': 512, 'activation_4': 'relu', 'units_5': 32, 'activation_5': 'elu', 'units_6': 32, 'activation_6': 'relu', 'units_7': 32, 'activation_7': 'relu', 'units_8': 32, 'activation_8': 'elu', 'units_9': 512, 'activation_9': 'elu'}\n","\n","Model performance rank : 2\n","{'num_layers': 9, 'units_0': 256, 'activation_0': 'relu', 'learning_rate': 0.001, 'units_1': 32, 'activation_1': 'relu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 32, 'activation_3': 'relu', 'units_4': 32, 'activation_4': 'relu', 'units_5': 32, 'activation_5': 'relu', 'units_6': 32, 'activation_6': 'relu', 'units_7': 32, 'activation_7': 'relu', 'units_8': 32, 'activation_8': 'relu'}\n","\n","\n","The hyperparameter search is complete. \n","* Optimal # of layers : 10\n","* Optimal value of the learning-rate : 0.0001\n","Layer 0 - # of Perceptrons : 512\n","Layer 0 - Applied activation function : relu\n","Layer 1 - # of Perceptrons : 512\n","Layer 1 - Applied activation function : relu\n","Layer 2 - # of Perceptrons : 32\n","Layer 2 - Applied activation function : relu\n","Layer 3 - # of Perceptrons : 32\n","Layer 3 - Applied activation function : relu\n","Layer 4 - # of Perceptrons : 32\n","Layer 4 - Applied activation function : relu\n","Layer 5 - # of Perceptrons : 32\n","Layer 5 - Applied activation function : relu\n","Layer 6 - # of Perceptrons : 32\n","Layer 6 - Applied activation function : elu\n","Layer 7 - # of Perceptrons : 32\n","Layer 7 - Applied activation function : elu\n","Layer 8 - # of Perceptrons : 512\n","Layer 8 - Applied activation function : relu\n","Layer 9 - # of Perceptrons : 512\n","Layer 9 - Applied activation function : elu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oO2QFJn0L7z_","executionInfo":{"elapsed":2264,"status":"ok","timestamp":1611880563165,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"5015ff13-6455-481b-ba7f-c3f31d9fdfaf"},"source":["# Get the best model from trials: accuracy 0.67\n","\n","models = tuner.get_best_models(num_models=3) # Keras Sequential models\n","top_model = models[0]\n","#top_model.summary()\n","print()\n","\n","results = top_model.evaluate(test_data, test_label)\n","print('Cross-entropy :', results[0])\n","print('Accuracy :', results[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","397/397 [==============================] - 1s 2ms/step - loss: 0.9326 - accuracy: 0.6665\n","Cross-entropy : 0.929269552230835\n","Accuracy : 0.6705011129379272\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3j5xYX3dOHqV","executionInfo":{"elapsed":77254,"status":"ok","timestamp":1611880673042,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"d35d341e-d132-4860-cb56-3b1b762de188"},"source":["# We can retrain the model with the optimal hyperparameters from the search.\n","best_hps = top3_models[0]\n","\n","# Build the model with the optimal hyperparameters and train it on the data.\n","model = tuner.hypermodel.build(best_hps)\n","model.fit(train_data, train_label, epochs=20, validation_data=(test_data, test_label))\n","\n","results = model.evaluate(test_data, test_label)\n","print('Cross-entropy :', results[0])\n","print('Accuracy :', results[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.8447 - accuracy: 0.3868 - val_loss: 1.1519 - val_accuracy: 0.5990\n","Epoch 2/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.1194 - accuracy: 0.6104 - val_loss: 1.0486 - val_accuracy: 0.6338\n","Epoch 3/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0288 - accuracy: 0.6385 - val_loss: 1.0064 - val_accuracy: 0.6395\n","Epoch 4/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9703 - accuracy: 0.6548 - val_loss: 0.9800 - val_accuracy: 0.6514\n","Epoch 5/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9381 - accuracy: 0.6682 - val_loss: 0.9608 - val_accuracy: 0.6573\n","Epoch 6/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9239 - accuracy: 0.6666 - val_loss: 0.9514 - val_accuracy: 0.6603\n","Epoch 7/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8945 - accuracy: 0.6789 - val_loss: 0.9662 - val_accuracy: 0.6562\n","Epoch 8/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8955 - accuracy: 0.6772 - val_loss: 0.9497 - val_accuracy: 0.6584\n","Epoch 9/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8813 - accuracy: 0.6795 - val_loss: 0.9486 - val_accuracy: 0.6617\n","Epoch 10/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8537 - accuracy: 0.6877 - val_loss: 0.9373 - val_accuracy: 0.6699\n","Epoch 11/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8496 - accuracy: 0.6914 - val_loss: 0.9463 - val_accuracy: 0.6647\n","Epoch 12/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8352 - accuracy: 0.6999 - val_loss: 0.9405 - val_accuracy: 0.6665\n","Epoch 13/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8169 - accuracy: 0.7040 - val_loss: 0.9314 - val_accuracy: 0.6702\n","Epoch 14/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8137 - accuracy: 0.7020 - val_loss: 0.9453 - val_accuracy: 0.6644\n","Epoch 15/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.8179 - accuracy: 0.7016 - val_loss: 0.9360 - val_accuracy: 0.6659\n","Epoch 16/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.7951 - accuracy: 0.7069 - val_loss: 0.9529 - val_accuracy: 0.6642\n","Epoch 17/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.7930 - accuracy: 0.7078 - val_loss: 0.9665 - val_accuracy: 0.6633\n","Epoch 18/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.7614 - accuracy: 0.7217 - val_loss: 0.9558 - val_accuracy: 0.6611\n","Epoch 19/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.7577 - accuracy: 0.7175 - val_loss: 0.9478 - val_accuracy: 0.6650\n","Epoch 20/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.7563 - accuracy: 0.7229 - val_loss: 0.9374 - val_accuracy: 0.6707\n","397/397 [==============================] - 1s 2ms/step - loss: 0.9374 - accuracy: 0.6707\n","Cross-entropy : 0.9373648762702942\n","Accuracy : 0.6707374453544617\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N53W-VP4X_6Y","executionInfo":{"elapsed":787,"status":"ok","timestamp":1611880719989,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"c475f5f5-2ea3-4c3d-8e96-8f959162e14d"},"source":["# We can also find detailed logs, checkpoints, etc, in the folder \"directory/project_name\".\n","\n","# The [test_prac_dir/MNIST_hyper_1] directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. \n","# If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n","# To disable this behavior, pass an additional [overwrite = True] argument while instantiating the tuner.\n","\n","for trial in tuner.oracle.get_best_trials(num_trials=3):\n","    print('Trial-score is :', trial.score)\n","    print('Trial-directory(trial_id) is :', trial.trial_id)\n","    print()\n","\n","# tuner.oracle.trials -> get all trial_id "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trial-score is : 0.6705011129379272\n","Trial-directory(trial_id) is : 172b075c6e0ed3e48cb768ba8dfaa5e5\n","\n","Trial-score is : 0.6691616773605347\n","Trial-directory(trial_id) is : 8fe89f4cf44b83bfd95415d33129cf59\n","\n","Trial-score is : 0.6667191982269287\n","Trial-directory(trial_id) is : 9058b8c7d43a7d5c7183fe1b5d71ee90\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WnpYDBdd_vUV"},"source":["# 1-2. Keras Tuner - with TopKCategoricalAccuracy(k=3)"]},{"cell_type":"code","metadata":{"id":"SRKS5SpH_Kn5"},"source":["import tensorflow as tf\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","from tensorflow import keras \n","from tensorflow.keras import layers\n","\n","import kerastuner as kt\n","import numpy as np\n","import IPython\n","\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Af3oO1_Kn6","executionInfo":{"status":"ok","timestamp":1612137577871,"user_tz":-540,"elapsed":17263,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"a2758445-5e31-41f6-8d70-52f4eb86c1e8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rLx4Ybp_Kn6","executionInfo":{"status":"ok","timestamp":1612137597844,"user_tz":-540,"elapsed":2143,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"b3705e11-5dcd-4e98-f673-beb1507fc13b"},"source":["# 미리 정리한 데이터 불러오기\r\n","train_data=np.load('/content/drive/MyDrive/Colab Notebooks/X_train_pro.npy')\r\n","test_data=np.load('/content/drive/MyDrive/Colab Notebooks/X_test_pro.npy')\r\n","train_label=np.load('/content/drive/MyDrive/Colab Notebooks/y_train_pro.npy')\r\n","test_label=np.load('/content/drive/MyDrive/Colab Notebooks/y_test_pro.npy')\r\n","\r\n","print(train_data.shape)\r\n","print(test_data.shape)\r\n","print(train_label.shape)\r\n","print(test_label.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(29613, 28)\n","(12692, 28)\n","(29613, 15)\n","(12692, 15)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L77vOVvu_Kn7"},"source":["# TopKCategoricalAccuracy(k=3)를 Keras-tuner에 적용\r\n","\r\n","def build_hyper_model(hp):\r\n","    \r\n","    model = keras.Sequential()\r\n","        \r\n","    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):  # 1 ~ 10개의 레이어로 설정\r\n","        hp_units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32) \r\n","        hp_activations = hp.Choice('activation_' + str(i), values=['relu', 'elu'])\r\n","        model.add(layers.Dense(units = hp_units, activation = hp_activations))\r\n","\r\n","    model.add(layers.Dense(15, activation='softmax')) # y_data(_label)의 shape 참조\r\n","\r\n","    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \r\n","    \r\n","    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\r\n","                loss = keras.losses.CategoricalCrossentropy(), \r\n","                # 아래의 기존 metrics를 TopKCategoricalAccuracy로 수정함.\r\n","                metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\r\n","                # metrics = ['accuracy'])\r\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbmCIsj24R9o","executionInfo":{"status":"ok","timestamp":1612137618173,"user_tz":-540,"elapsed":6618,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"50356792-795e-45b3-e71c-085e64bea9f2"},"source":["tuner = kt.BayesianOptimization(build_hyper_model,\r\n","                                objective = 'top_k_categorical_accuracy', # Top 3 정확도로 수정\r\n","                                max_trials = 10, \r\n","                                directory = 'test_prac_dir',\r\n","                                project_name = 'Spotify_hyper_6') \r\n","\r\n","tuner.search_space_summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Search space summary\n","Default search space size: 4\n","num_layers (Int)\n","{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': None}\n","units_0 (Int)\n","{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n","activation_0 (Choice)\n","{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n","learning_rate (Choice)\n","{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9GKjxxw_Kn7","executionInfo":{"status":"ok","timestamp":1612138325975,"user_tz":-540,"elapsed":701512,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"cc847348-55c1-483d-cd46-52915820b262"},"source":["# 시간이 너무 오래 걸려서.. epochs를 20으로 설정했습니다.\n","tuner.search(train_data, train_label, epochs=20, validation_data = (test_data, test_label)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trial 10 Complete [00h 01m 11s]\n","top_k_categorical_accuracy: 0.745348334312439\n","\n","Best top_k_categorical_accuracy So Far: 0.5344274640083313\n","Total elapsed time: 00h 11m 40s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfUTD43n_Kn8","executionInfo":{"status":"ok","timestamp":1612095570322,"user_tz":-540,"elapsed":698,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"e3cdd107-9cbf-4228-c2f6-69ed8d57f34a"},"source":["# 가장 성능 좋은 모델 3개 추출\n","tuner.results_summary(num_trials=3) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Results summary\n","Results in test_prac_dir/Spotify_hyper_5\n","Showing 3 best trials\n","Objective(name='accuracy', direction='max')\n","Trial summary\n","Hyperparameters:\n","num_layers: 6\n","units_0: 96\n","activation_0: elu\n","learning_rate: 0.001\n","units_1: 480\n","activation_1: relu\n","units_2: 192\n","activation_2: elu\n","units_3: 160\n","activation_3: relu\n","units_4: 352\n","activation_4: elu\n","units_5: 224\n","activation_5: elu\n","units_6: 480\n","activation_6: relu\n","units_7: 64\n","activation_7: relu\n","units_8: 352\n","activation_8: relu\n","Score: 0.9589505195617676\n","Trial summary\n","Hyperparameters:\n","num_layers: 9\n","units_0: 96\n","activation_0: relu\n","learning_rate: 0.001\n","units_1: 32\n","activation_1: relu\n","units_2: 32\n","activation_2: relu\n","units_3: 32\n","activation_3: relu\n","units_4: 32\n","activation_4: relu\n","units_5: 32\n","activation_5: relu\n","units_6: 32\n","activation_6: relu\n","units_7: 32\n","activation_7: relu\n","units_8: 32\n","activation_8: relu\n","Score: 0.9314528703689575\n","Trial summary\n","Hyperparameters:\n","num_layers: 1\n","units_0: 512\n","activation_0: relu\n","learning_rate: 0.0001\n","units_1: 32\n","activation_1: elu\n","units_2: 512\n","activation_2: relu\n","units_3: 512\n","activation_3: elu\n","units_4: 32\n","activation_4: relu\n","units_5: 32\n","activation_5: relu\n","units_6: 32\n","activation_6: elu\n","units_7: 512\n","activation_7: elu\n","units_8: 512\n","activation_8: elu\n","Score: 0.9307437539100647\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y6fMXqb1_Kn8","executionInfo":{"status":"ok","timestamp":1612138347335,"user_tz":-540,"elapsed":594,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"85edae43-e69f-409f-b36b-624d2e9775fe"},"source":["# top-3 trials' hyper-params 확인\n","\n","top3_models = tuner.get_best_hyperparameters(num_trials=3)\n","\n","for idx, model in enumerate(top3_models):\n","    print('Model performance rank :', idx)\n","    print(model.values)\n","    print()\n","\n","\n","# the best trial's hyper-params 확인\n","\n","best_hps = top3_models[0]\n","\n","print(\"\"\"\n","The hyperparameter search is complete. \n","* Optimal # of layers : {}\n","* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n","\n","for layer_num in range(best_hps.get('num_layers')):\n","    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n","    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model performance rank : 0\n","{'num_layers': 10, 'units_0': 32, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 32, 'activation_1': 'elu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 32, 'activation_3': 'elu', 'units_4': 512, 'activation_4': 'elu', 'units_5': 32, 'activation_5': 'relu', 'units_6': 32, 'activation_6': 'relu', 'units_7': 32, 'activation_7': 'relu', 'units_8': 32, 'activation_8': 'relu', 'units_9': 32, 'activation_9': 'relu'}\n","\n","Model performance rank : 1\n","{'num_layers': 10, 'units_0': 32, 'activation_0': 'relu', 'learning_rate': 0.0001, 'units_1': 512, 'activation_1': 'elu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 32, 'activation_3': 'elu', 'units_4': 512, 'activation_4': 'elu', 'units_5': 32, 'activation_5': 'elu', 'units_6': 32, 'activation_6': 'elu', 'units_7': 512, 'activation_7': 'relu', 'units_8': 32, 'activation_8': 'relu', 'units_9': 32, 'activation_9': 'relu'}\n","\n","Model performance rank : 2\n","{'num_layers': 10, 'units_0': 512, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 32, 'activation_1': 'elu', 'units_2': 32, 'activation_2': 'relu', 'units_3': 512, 'activation_3': 'elu', 'units_4': 512, 'activation_4': 'elu', 'units_5': 512, 'activation_5': 'elu', 'units_6': 32, 'activation_6': 'elu', 'units_7': 32, 'activation_7': 'relu', 'units_8': 32, 'activation_8': 'relu', 'units_9': 32, 'activation_9': 'relu'}\n","\n","\n","The hyperparameter search is complete. \n","* Optimal # of layers : 10\n","* Optimal value of the learning-rate : 0.0001\n","Layer 0 - # of Perceptrons : 32\n","Layer 0 - Applied activation function : elu\n","Layer 1 - # of Perceptrons : 32\n","Layer 1 - Applied activation function : elu\n","Layer 2 - # of Perceptrons : 32\n","Layer 2 - Applied activation function : relu\n","Layer 3 - # of Perceptrons : 32\n","Layer 3 - Applied activation function : elu\n","Layer 4 - # of Perceptrons : 512\n","Layer 4 - Applied activation function : elu\n","Layer 5 - # of Perceptrons : 32\n","Layer 5 - Applied activation function : relu\n","Layer 6 - # of Perceptrons : 32\n","Layer 6 - Applied activation function : relu\n","Layer 7 - # of Perceptrons : 32\n","Layer 7 - Applied activation function : relu\n","Layer 8 - # of Perceptrons : 32\n","Layer 8 - Applied activation function : relu\n","Layer 9 - # of Perceptrons : 32\n","Layer 9 - Applied activation function : relu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pvr2Stvq_Kn8","executionInfo":{"status":"ok","timestamp":1612138582180,"user_tz":-540,"elapsed":71962,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"3064065b-d302-4e57-c870-f73bb74530c2"},"source":["# 가장 성능 좋은 모델로 epochs 20으로 fit\n","best_hps = top3_models[0]\n","\n","model = tuner.hypermodel.build(best_hps)\n","model.fit(train_data, train_label, epochs=20, validation_data=(test_data, test_label))\n","\n","results = model.evaluate(test_data, test_label)\n","print('Cross-entropy :', results[0])\n","print('Accuracy :', results[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","926/926 [==============================] - 4s 4ms/step - loss: 2.3889 - top_k_categorical_accuracy: 0.4383 - val_loss: 1.5543 - val_top_k_categorical_accuracy: 0.7769\n","Epoch 2/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.5112 - top_k_categorical_accuracy: 0.7822 - val_loss: 1.3648 - val_top_k_categorical_accuracy: 0.8071\n","Epoch 3/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.3460 - top_k_categorical_accuracy: 0.8132 - val_loss: 1.2802 - val_top_k_categorical_accuracy: 0.8287\n","Epoch 4/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.2568 - top_k_categorical_accuracy: 0.8354 - val_loss: 1.2232 - val_top_k_categorical_accuracy: 0.8442\n","Epoch 5/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.1904 - top_k_categorical_accuracy: 0.8480 - val_loss: 1.1626 - val_top_k_categorical_accuracy: 0.8583\n","Epoch 6/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.1438 - top_k_categorical_accuracy: 0.8557 - val_loss: 1.1323 - val_top_k_categorical_accuracy: 0.8628\n","Epoch 7/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.1151 - top_k_categorical_accuracy: 0.8644 - val_loss: 1.1006 - val_top_k_categorical_accuracy: 0.8686\n","Epoch 8/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.0847 - top_k_categorical_accuracy: 0.8727 - val_loss: 1.1076 - val_top_k_categorical_accuracy: 0.8693\n","Epoch 9/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.0529 - top_k_categorical_accuracy: 0.8809 - val_loss: 1.0684 - val_top_k_categorical_accuracy: 0.8741\n","Epoch 10/20\n","926/926 [==============================] - 3s 4ms/step - loss: 1.0499 - top_k_categorical_accuracy: 0.8783 - val_loss: 1.0653 - val_top_k_categorical_accuracy: 0.8746\n","Epoch 11/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0395 - top_k_categorical_accuracy: 0.8819 - val_loss: 1.0441 - val_top_k_categorical_accuracy: 0.8821\n","Epoch 12/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0229 - top_k_categorical_accuracy: 0.8862 - val_loss: 1.0336 - val_top_k_categorical_accuracy: 0.8833\n","Epoch 13/20\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0069 - top_k_categorical_accuracy: 0.8878 - val_loss: 1.0333 - val_top_k_categorical_accuracy: 0.8824\n","Epoch 14/20\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9969 - top_k_categorical_accuracy: 0.8916 - val_loss: 1.0365 - val_top_k_categorical_accuracy: 0.8800\n","Epoch 15/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9924 - top_k_categorical_accuracy: 0.8924 - val_loss: 1.0191 - val_top_k_categorical_accuracy: 0.8839\n","Epoch 16/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9854 - top_k_categorical_accuracy: 0.8937 - val_loss: 1.0191 - val_top_k_categorical_accuracy: 0.8873\n","Epoch 17/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9944 - top_k_categorical_accuracy: 0.8916 - val_loss: 1.0249 - val_top_k_categorical_accuracy: 0.8831\n","Epoch 18/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9820 - top_k_categorical_accuracy: 0.8917 - val_loss: 1.0089 - val_top_k_categorical_accuracy: 0.8891\n","Epoch 19/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9693 - top_k_categorical_accuracy: 0.8952 - val_loss: 1.0011 - val_top_k_categorical_accuracy: 0.8879\n","Epoch 20/20\n","926/926 [==============================] - 3s 4ms/step - loss: 0.9642 - top_k_categorical_accuracy: 0.8968 - val_loss: 0.9932 - val_top_k_categorical_accuracy: 0.8889\n","397/397 [==============================] - 1s 2ms/step - loss: 0.9932 - top_k_categorical_accuracy: 0.8889\n","Cross-entropy : 0.9931907057762146\n","Accuracy : 0.8889064192771912\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LsRHAGHQAb8X"},"source":["import matplotlib.pyplot as plt\r\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jaDz5UMVAbxb","executionInfo":{"status":"ok","timestamp":1612140108179,"user_tz":-540,"elapsed":17295,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"9f80e619-4a5c-4cf7-bd71-d8b37c102a4e"},"source":["# AUC curve를 그리기 위해 기록\r\n","\r\n","history = model.fit(train_data, train_label, batch_size=100, epochs=20, validation_split=0.3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9240 - top_k_categorical_accuracy: 0.9052 - val_loss: 0.9621 - val_top_k_categorical_accuracy: 0.8950\n","Epoch 2/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9219 - top_k_categorical_accuracy: 0.9075 - val_loss: 0.9679 - val_top_k_categorical_accuracy: 0.8914\n","Epoch 3/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9206 - top_k_categorical_accuracy: 0.9059 - val_loss: 0.9713 - val_top_k_categorical_accuracy: 0.8930\n","Epoch 4/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9189 - top_k_categorical_accuracy: 0.9050 - val_loss: 0.9627 - val_top_k_categorical_accuracy: 0.8930\n","Epoch 5/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9179 - top_k_categorical_accuracy: 0.9052 - val_loss: 0.9639 - val_top_k_categorical_accuracy: 0.8927\n","Epoch 6/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9172 - top_k_categorical_accuracy: 0.9067 - val_loss: 0.9600 - val_top_k_categorical_accuracy: 0.8949\n","Epoch 7/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9150 - top_k_categorical_accuracy: 0.9056 - val_loss: 0.9618 - val_top_k_categorical_accuracy: 0.8953\n","Epoch 8/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9151 - top_k_categorical_accuracy: 0.9080 - val_loss: 0.9605 - val_top_k_categorical_accuracy: 0.8963\n","Epoch 9/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9143 - top_k_categorical_accuracy: 0.9077 - val_loss: 0.9601 - val_top_k_categorical_accuracy: 0.8946\n","Epoch 10/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9131 - top_k_categorical_accuracy: 0.9082 - val_loss: 0.9617 - val_top_k_categorical_accuracy: 0.8952\n","Epoch 11/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9145 - top_k_categorical_accuracy: 0.9084 - val_loss: 0.9643 - val_top_k_categorical_accuracy: 0.8946\n","Epoch 12/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9104 - top_k_categorical_accuracy: 0.9072 - val_loss: 0.9598 - val_top_k_categorical_accuracy: 0.8957\n","Epoch 13/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9097 - top_k_categorical_accuracy: 0.9075 - val_loss: 0.9704 - val_top_k_categorical_accuracy: 0.8923\n","Epoch 14/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9097 - top_k_categorical_accuracy: 0.9093 - val_loss: 0.9574 - val_top_k_categorical_accuracy: 0.8939\n","Epoch 15/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9082 - top_k_categorical_accuracy: 0.9090 - val_loss: 0.9579 - val_top_k_categorical_accuracy: 0.8958\n","Epoch 16/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9073 - top_k_categorical_accuracy: 0.9074 - val_loss: 0.9647 - val_top_k_categorical_accuracy: 0.8941\n","Epoch 17/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9068 - top_k_categorical_accuracy: 0.9093 - val_loss: 0.9632 - val_top_k_categorical_accuracy: 0.8948\n","Epoch 18/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9048 - top_k_categorical_accuracy: 0.9080 - val_loss: 0.9547 - val_top_k_categorical_accuracy: 0.8964\n","Epoch 19/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9054 - top_k_categorical_accuracy: 0.9088 - val_loss: 0.9580 - val_top_k_categorical_accuracy: 0.8955\n","Epoch 20/20\n","208/208 [==============================] - 1s 4ms/step - loss: 0.9028 - top_k_categorical_accuracy: 0.9084 - val_loss: 0.9606 - val_top_k_categorical_accuracy: 0.8952\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"_q3uZJU7Abny","executionInfo":{"status":"ok","timestamp":1612140115558,"user_tz":-540,"elapsed":674,"user":{"displayName":"김연주","photoUrl":"","userId":"02317915846790322311"}},"outputId":"ef880a8c-3538-4fbd-d046-198644728726"},"source":["# top_k_categorical_accuracy를 기준으로 그린 AUC curve \r\n","\r\n","acc = history.history['top_k_categorical_accuracy']\r\n","val_acc = history.history['val_top_k_categorical_accuracy']\r\n","\r\n","x_len = np.arange(len(acc))\r\n","\r\n","plt.plot(x_len, acc, marker='.', c='blue', label=\"Train-set Acc.\")\r\n","plt.plot(x_len, val_acc, marker='.', c='red', label=\"Validation-set Acc.\")\r\n","\r\n","plt.legend(loc='upper right')\r\n","plt.grid()\r\n","plt.xlabel('epoch')\r\n","plt.ylabel('Accuracy')\r\n","\r\n","# AUC curve 구글 콜랩에서 다운로드\r\n","from google.colab import files\r\n","plt.savefig(\"top_k_auc_curve.png\")\r\n","files.download(\"top_k_auc_curve.png\") \r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_7e61b65d-ac71-4449-9407-8e47480660e3\", \"top_k_auc_curve.png\", 22642)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"kZqGDaP_jk5k"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyPWPJmhtLgj"},"source":["# 2. Auto Keras"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2qNvSkRtPFa","executionInfo":{"elapsed":7533,"status":"ok","timestamp":1611886152811,"user":{"displayName":"Hazel Kang","photoUrl":"","userId":"09199737328986746816"},"user_tz":-540},"outputId":"d75e29d8-fb39-44c3-ecf2-ac06b456d1f3"},"source":["!pip install autokeras"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting autokeras\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n","\r\u001b[K     |██                              | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 30.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 23.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 22.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 25.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 143kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 153kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 17.2MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.1.5)\n","Collecting keras-tuner>=1.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n","\r\u001b[K     |█████▏                          | 10kB 30.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 38.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 42.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 42.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 44.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 37.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from autokeras) (20.8)\n","Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.22.2.post1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.7)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (1.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->autokeras) (2.4.7)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.1)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.10.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (51.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n","Building wheels for collected packages: keras-tuner, terminaltables\n","  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=1a6fb6f3d8983d822f006cdc38b06f69ac9394f6f29b005af01dfe0037065fe0\n","  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=172a234c3143f2b66645bc7644eddacb2286c6dbec5f79201071cd1bd7de9ff0\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built keras-tuner terminaltables\n","Installing collected packages: terminaltables, colorama, keras-tuner, autokeras\n","Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U46MjWEyvBmk"},"source":["import autokeras as ak"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"PxXQUwAIvC8f","outputId":"4e9b6b38-c90c-4e5c-afcc-eb08b98d268a"},"source":["#https://machinelearningmastery.com/autokeras-for-classification-and-regression/\r\n","#https://autokeras.com/tutorial/structured_data_classification/\r\n","model = ak.StructuredDataClassifier(max_trials=10) # It searches CNN architectures for the best configuration for the image dataset.\r\n","model.fit(train_data, train_label) # time_limit: The time limit for the search in seconds.\r\n","\r\n","accuracy = model.evaluate(test_data, test_label)\r\n","result = model.predict(test_data)\r\n","\r\n","print(accuracy)\r\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trial 10 Complete [00h 01m 28s]\n","val_accuracy: 0.6024402379989624\n","\n","Best val_accuracy So Far: 0.6193865537643433\n","Total elapsed time: 00h 40m 03s\n","Epoch 1/75\n","926/926 [==============================] - 4s 4ms/step - loss: 2.1198 - accuracy: 0.2964\n","Epoch 2/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.3505 - accuracy: 0.5376\n","Epoch 3/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.2307 - accuracy: 0.5734\n","Epoch 4/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.1700 - accuracy: 0.5905\n","Epoch 5/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.1338 - accuracy: 0.5968\n","Epoch 6/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.1100 - accuracy: 0.6034\n","Epoch 7/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0927 - accuracy: 0.6080\n","Epoch 8/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0791 - accuracy: 0.6119\n","Epoch 9/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0684 - accuracy: 0.6142\n","Epoch 10/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0600 - accuracy: 0.6178\n","Epoch 11/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0526 - accuracy: 0.6219\n","Epoch 12/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0459 - accuracy: 0.6251\n","Epoch 13/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0398 - accuracy: 0.6257\n","Epoch 14/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0350 - accuracy: 0.6267\n","Epoch 15/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0305 - accuracy: 0.6281\n","Epoch 16/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0267 - accuracy: 0.6302\n","Epoch 17/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0231 - accuracy: 0.6308\n","Epoch 18/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0200 - accuracy: 0.6320\n","Epoch 19/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0171 - accuracy: 0.6327\n","Epoch 20/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0147 - accuracy: 0.6329\n","Epoch 21/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0122 - accuracy: 0.6326\n","Epoch 22/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0095 - accuracy: 0.6343\n","Epoch 23/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0074 - accuracy: 0.6357\n","Epoch 24/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0055 - accuracy: 0.6349\n","Epoch 25/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0041 - accuracy: 0.6365\n","Epoch 26/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0024 - accuracy: 0.6361\n","Epoch 27/75\n","926/926 [==============================] - 4s 4ms/step - loss: 1.0009 - accuracy: 0.6370\n","Epoch 28/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9996 - accuracy: 0.6381\n","Epoch 29/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9981 - accuracy: 0.6378\n","Epoch 30/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9967 - accuracy: 0.6378\n","Epoch 31/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9954 - accuracy: 0.6382\n","Epoch 32/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9941 - accuracy: 0.6381\n","Epoch 33/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9930 - accuracy: 0.6393\n","Epoch 34/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9919 - accuracy: 0.6394\n","Epoch 35/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9910 - accuracy: 0.6405\n","Epoch 36/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9899 - accuracy: 0.6403\n","Epoch 37/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9890 - accuracy: 0.6409\n","Epoch 38/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9881 - accuracy: 0.6401\n","Epoch 39/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9873 - accuracy: 0.6407\n","Epoch 40/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9863 - accuracy: 0.6411\n","Epoch 41/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9854 - accuracy: 0.6412\n","Epoch 42/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9844 - accuracy: 0.6413\n","Epoch 43/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9835 - accuracy: 0.6418\n","Epoch 44/75\n","926/926 [==============================] - 4s 5ms/step - loss: 0.9827 - accuracy: 0.6419\n","Epoch 45/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9821 - accuracy: 0.6417\n","Epoch 46/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9816 - accuracy: 0.6421\n","Epoch 47/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9807 - accuracy: 0.6427\n","Epoch 48/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9799 - accuracy: 0.6434\n","Epoch 49/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9793 - accuracy: 0.6440\n","Epoch 50/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9788 - accuracy: 0.6442\n","Epoch 51/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9782 - accuracy: 0.6440\n","Epoch 52/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9774 - accuracy: 0.6442\n","Epoch 53/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9772 - accuracy: 0.6446\n","Epoch 54/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9764 - accuracy: 0.6449\n","Epoch 55/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9761 - accuracy: 0.6460\n","Epoch 56/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9753 - accuracy: 0.6463\n","Epoch 57/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9748 - accuracy: 0.6458\n","Epoch 58/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9744 - accuracy: 0.6458\n","Epoch 59/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9742 - accuracy: 0.6465\n","Epoch 60/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9733 - accuracy: 0.6466\n","Epoch 61/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9729 - accuracy: 0.6474\n","Epoch 62/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9723 - accuracy: 0.6475\n","Epoch 63/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9720 - accuracy: 0.6477\n","Epoch 64/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9712 - accuracy: 0.6480\n","Epoch 65/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9710 - accuracy: 0.6475\n","Epoch 66/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9705 - accuracy: 0.6482\n","Epoch 67/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9704 - accuracy: 0.6483\n","Epoch 68/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9698 - accuracy: 0.6482\n","Epoch 69/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9693 - accuracy: 0.6482\n","Epoch 70/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9692 - accuracy: 0.6483\n","Epoch 71/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9681 - accuracy: 0.6486\n","Epoch 72/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9683 - accuracy: 0.6483\n","Epoch 73/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9674 - accuracy: 0.6488\n","Epoch 74/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9674 - accuracy: 0.6484\n","Epoch 75/75\n","926/926 [==============================] - 4s 4ms/step - loss: 0.9668 - accuracy: 0.6488\n","397/397 [==============================] - 2s 4ms/step - loss: 1.0514 - accuracy: 0.6226\n","[1.051382303237915, 0.6225969195365906]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]}]}